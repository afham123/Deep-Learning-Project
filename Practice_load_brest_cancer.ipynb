{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice_load_brest_cancer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVAM5rg6A7NeYxznwsRCOD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afham123/Deep-Learning-Project/blob/main/Practice_load_brest_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdwzIQDvSHc0"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJCkevgCSXB3"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\r\n",
        "data=load_breast_cancer()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLc1qXzoVpSj",
        "outputId": "2085f728-a262-4f14-908e-a697791c8b2f"
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHb_hxOkVzHP",
        "outputId": "fc906946-e286-4d74-e814-7ab567a5355e"
      },
      "source": [
        "data['feature_names']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "h1r9J2HuV_Ko",
        "outputId": "d9521db7-2c60-44fd-be9e-e668c693fa28"
      },
      "source": [
        "df=pd.DataFrame(data=data['data'],columns=data['feature_names'])\r\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6SyEbK9WNnU",
        "outputId": "64a34986-e001-4b02-9322-93226391f64a"
      },
      "source": [
        "print(data['DESCR'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry \n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
            "        13 is Radius SE, field 23 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WROOroZ-Wi46"
      },
      "source": [
        "y=data['target']\r\n",
        "X=df"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xJbKkqWWocb",
        "outputId": "d66d5959-7b1d-4423-e09a-2806419eac77"
      },
      "source": [
        "print(data['target_names'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['malignant' 'benign']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kweha_QBWoPn",
        "outputId": "c05734fc-e9c3-479d-cfe0-1d60f63e4ea7"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIt6qUZ5W5B-",
        "outputId": "d39bf3eb-fb9d-4af4-ea5c-9d4bd84fee67"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "3iM2nfi0XCfi",
        "outputId": "e8fdb97e-3bdd-4736-eccf-c47738f28deb"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "count   569.000000    569.000000  ...      569.000000               569.000000\n",
              "mean     14.127292     19.289649  ...        0.290076                 0.083946\n",
              "std       3.524049      4.301036  ...        0.061867                 0.018061\n",
              "min       6.981000      9.710000  ...        0.156500                 0.055040\n",
              "25%      11.700000     16.170000  ...        0.250400                 0.071460\n",
              "50%      13.370000     18.840000  ...        0.282200                 0.080040\n",
              "75%      15.780000     21.800000  ...        0.317900                 0.092080\n",
              "max      28.110000     39.280000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDturtiQXENc"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecDPrtG6XFwi"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OANJ4eCEXFja"
      },
      "source": [
        "from tensorflow.keras.layers import Dense,Dropout\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNtaOpRyXh77"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nSoDMBgXyHG"
      },
      "source": [
        "scaler=StandardScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "X_train=scaler.transform(X_train)\r\n",
        "X_test=scaler.transform(X_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIKg7AzcX3vu"
      },
      "source": [
        "model=Sequential()\r\n",
        "\r\n",
        "model.add(Dense(30,activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Dense(30,activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Dense(15,activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Dense(7,activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY148icpYQbi",
        "outputId": "0f193c9d-2694-41de-dd80-ae304e51cc11"
      },
      "source": [
        "early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=20)\r\n",
        "model.fit(X_train,y_train,epochs=500,batch_size=256,validation_data=(X_test,y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.0639 - accuracy: 0.9673 - val_loss: 0.1747 - val_accuracy: 0.9649\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0579 - accuracy: 0.9648 - val_loss: 0.1752 - val_accuracy: 0.9649\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0462 - accuracy: 0.9799 - val_loss: 0.1762 - val_accuracy: 0.9649\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0440 - accuracy: 0.9774 - val_loss: 0.1776 - val_accuracy: 0.9649\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 0.1796 - val_accuracy: 0.9649\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0691 - accuracy: 0.9623 - val_loss: 0.1812 - val_accuracy: 0.9649\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0421 - accuracy: 0.9774 - val_loss: 0.1832 - val_accuracy: 0.9649\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 0.1853 - val_accuracy: 0.9649\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0541 - accuracy: 0.9724 - val_loss: 0.1871 - val_accuracy: 0.9649\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0462 - accuracy: 0.9824 - val_loss: 0.1890 - val_accuracy: 0.9649\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0422 - accuracy: 0.9799 - val_loss: 0.1908 - val_accuracy: 0.9649\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0470 - accuracy: 0.9698 - val_loss: 0.1918 - val_accuracy: 0.9649\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0425 - accuracy: 0.9724 - val_loss: 0.1926 - val_accuracy: 0.9649\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0383 - accuracy: 0.9824 - val_loss: 0.1933 - val_accuracy: 0.9649\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0404 - accuracy: 0.9799 - val_loss: 0.1944 - val_accuracy: 0.9649\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0407 - accuracy: 0.9749 - val_loss: 0.1959 - val_accuracy: 0.9649\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0372 - accuracy: 0.9849 - val_loss: 0.1977 - val_accuracy: 0.9649\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0471 - accuracy: 0.9774 - val_loss: 0.1990 - val_accuracy: 0.9649\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0418 - accuracy: 0.9849 - val_loss: 0.2005 - val_accuracy: 0.9649\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0416 - accuracy: 0.9774 - val_loss: 0.2017 - val_accuracy: 0.9649\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0425 - accuracy: 0.9799 - val_loss: 0.2022 - val_accuracy: 0.9649\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0334 - accuracy: 0.9799 - val_loss: 0.2022 - val_accuracy: 0.9649\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0339 - accuracy: 0.9774 - val_loss: 0.2015 - val_accuracy: 0.9649\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0384 - accuracy: 0.9849 - val_loss: 0.2013 - val_accuracy: 0.9649\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0384 - accuracy: 0.9799 - val_loss: 0.2013 - val_accuracy: 0.9649\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0424 - accuracy: 0.9698 - val_loss: 0.2014 - val_accuracy: 0.9649\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0322 - accuracy: 0.9824 - val_loss: 0.2019 - val_accuracy: 0.9649\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0329 - accuracy: 0.9824 - val_loss: 0.2027 - val_accuracy: 0.9649\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0480 - accuracy: 0.9648 - val_loss: 0.2038 - val_accuracy: 0.9649\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0371 - accuracy: 0.9749 - val_loss: 0.2044 - val_accuracy: 0.9649\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0323 - accuracy: 0.9799 - val_loss: 0.2047 - val_accuracy: 0.9649\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0446 - accuracy: 0.9648 - val_loss: 0.2054 - val_accuracy: 0.9649\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0417 - accuracy: 0.9724 - val_loss: 0.2066 - val_accuracy: 0.9649\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0433 - accuracy: 0.9623 - val_loss: 0.2078 - val_accuracy: 0.9649\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0430 - accuracy: 0.9774 - val_loss: 0.2088 - val_accuracy: 0.9649\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0426 - accuracy: 0.9724 - val_loss: 0.2097 - val_accuracy: 0.9649\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0554 - accuracy: 0.9598 - val_loss: 0.2107 - val_accuracy: 0.9649\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0414 - accuracy: 0.9774 - val_loss: 0.2118 - val_accuracy: 0.9649\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0323 - accuracy: 0.9774 - val_loss: 0.2126 - val_accuracy: 0.9649\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 0.2138 - val_accuracy: 0.9649\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0322 - accuracy: 0.9799 - val_loss: 0.2155 - val_accuracy: 0.9649\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0444 - accuracy: 0.9749 - val_loss: 0.2175 - val_accuracy: 0.9649\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.2194 - val_accuracy: 0.9649\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 0.0332 - accuracy: 0.9799 - val_loss: 0.2214 - val_accuracy: 0.9649\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0397 - accuracy: 0.9799 - val_loss: 0.2230 - val_accuracy: 0.9649\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0243 - accuracy: 0.9849 - val_loss: 0.2244 - val_accuracy: 0.9649\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0279 - accuracy: 0.9799 - val_loss: 0.2260 - val_accuracy: 0.9649\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0259 - accuracy: 0.9874 - val_loss: 0.2274 - val_accuracy: 0.9649\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0260 - accuracy: 0.9824 - val_loss: 0.2280 - val_accuracy: 0.9649\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0283 - accuracy: 0.9874 - val_loss: 0.2291 - val_accuracy: 0.9649\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0295 - accuracy: 0.9824 - val_loss: 0.2302 - val_accuracy: 0.9649\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0285 - accuracy: 0.9799 - val_loss: 0.2324 - val_accuracy: 0.9649\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0376 - accuracy: 0.9824 - val_loss: 0.2353 - val_accuracy: 0.9649\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0379 - accuracy: 0.9774 - val_loss: 0.2375 - val_accuracy: 0.9649\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0281 - accuracy: 0.9799 - val_loss: 0.2391 - val_accuracy: 0.9649\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0280 - accuracy: 0.9849 - val_loss: 0.2404 - val_accuracy: 0.9649\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0323 - accuracy: 0.9774 - val_loss: 0.2417 - val_accuracy: 0.9649\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0285 - accuracy: 0.9849 - val_loss: 0.2430 - val_accuracy: 0.9708\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0257 - accuracy: 0.9849 - val_loss: 0.2446 - val_accuracy: 0.9708\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0256 - accuracy: 0.9799 - val_loss: 0.2467 - val_accuracy: 0.9708\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0298 - accuracy: 0.9774 - val_loss: 0.2493 - val_accuracy: 0.9708\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0270 - accuracy: 0.9799 - val_loss: 0.2513 - val_accuracy: 0.9708\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0175 - accuracy: 0.9899 - val_loss: 0.2535 - val_accuracy: 0.9708\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0214 - accuracy: 0.9874 - val_loss: 0.2556 - val_accuracy: 0.9708\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0283 - accuracy: 0.9824 - val_loss: 0.2572 - val_accuracy: 0.9708\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0253 - accuracy: 0.9899 - val_loss: 0.2586 - val_accuracy: 0.9708\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0228 - accuracy: 0.9874 - val_loss: 0.2588 - val_accuracy: 0.9708\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0344 - accuracy: 0.9724 - val_loss: 0.2584 - val_accuracy: 0.9708\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0324 - accuracy: 0.9774 - val_loss: 0.2562 - val_accuracy: 0.9708\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0360 - accuracy: 0.9774 - val_loss: 0.2546 - val_accuracy: 0.9708\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0334 - accuracy: 0.9824 - val_loss: 0.2537 - val_accuracy: 0.9708\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0194 - accuracy: 0.9874 - val_loss: 0.2535 - val_accuracy: 0.9708\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0368 - accuracy: 0.9799 - val_loss: 0.2537 - val_accuracy: 0.9708\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0368 - accuracy: 0.9774 - val_loss: 0.2545 - val_accuracy: 0.9708\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0233 - accuracy: 0.9849 - val_loss: 0.2554 - val_accuracy: 0.9708\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0348 - accuracy: 0.9724 - val_loss: 0.2561 - val_accuracy: 0.9708\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0267 - accuracy: 0.9799 - val_loss: 0.2573 - val_accuracy: 0.9708\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0242 - accuracy: 0.9849 - val_loss: 0.2588 - val_accuracy: 0.9708\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0202 - accuracy: 0.9849 - val_loss: 0.2603 - val_accuracy: 0.9708\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0212 - accuracy: 0.9799 - val_loss: 0.2619 - val_accuracy: 0.9708\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0204 - accuracy: 0.9849 - val_loss: 0.2639 - val_accuracy: 0.9708\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0267 - accuracy: 0.9774 - val_loss: 0.2656 - val_accuracy: 0.9708\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0230 - accuracy: 0.9774 - val_loss: 0.2670 - val_accuracy: 0.9708\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0375 - accuracy: 0.9799 - val_loss: 0.2671 - val_accuracy: 0.9708\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0560 - accuracy: 0.9698 - val_loss: 0.2669 - val_accuracy: 0.9708\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0208 - accuracy: 0.9824 - val_loss: 0.2676 - val_accuracy: 0.9708\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0344 - accuracy: 0.9698 - val_loss: 0.2678 - val_accuracy: 0.9708\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0248 - accuracy: 0.9874 - val_loss: 0.2680 - val_accuracy: 0.9708\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0373 - accuracy: 0.9774 - val_loss: 0.2679 - val_accuracy: 0.9708\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0240 - accuracy: 0.9774 - val_loss: 0.2683 - val_accuracy: 0.9708\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0353 - accuracy: 0.9724 - val_loss: 0.2684 - val_accuracy: 0.9708\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.0385 - accuracy: 0.9799 - val_loss: 0.2679 - val_accuracy: 0.9708\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0266 - accuracy: 0.9824 - val_loss: 0.2666 - val_accuracy: 0.9708\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0227 - accuracy: 0.9874 - val_loss: 0.2658 - val_accuracy: 0.9708\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0378 - accuracy: 0.9824 - val_loss: 0.2648 - val_accuracy: 0.9708\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0223 - accuracy: 0.9849 - val_loss: 0.2652 - val_accuracy: 0.9708\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0305 - accuracy: 0.9799 - val_loss: 0.2668 - val_accuracy: 0.9708\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0214 - accuracy: 0.9824 - val_loss: 0.2689 - val_accuracy: 0.9708\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0213 - accuracy: 0.9824 - val_loss: 0.2706 - val_accuracy: 0.9708\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0130 - accuracy: 0.9925 - val_loss: 0.2716 - val_accuracy: 0.9708\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0191 - accuracy: 0.9849 - val_loss: 0.2726 - val_accuracy: 0.9708\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0365 - accuracy: 0.9799 - val_loss: 0.2730 - val_accuracy: 0.9708\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0218 - accuracy: 0.9849 - val_loss: 0.2731 - val_accuracy: 0.9708\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0204 - accuracy: 0.9874 - val_loss: 0.2731 - val_accuracy: 0.9708\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0117 - accuracy: 0.9925 - val_loss: 0.2733 - val_accuracy: 0.9708\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0153 - accuracy: 0.9874 - val_loss: 0.2736 - val_accuracy: 0.9708\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0187 - accuracy: 0.9849 - val_loss: 0.2737 - val_accuracy: 0.9708\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0352 - accuracy: 0.9673 - val_loss: 0.2736 - val_accuracy: 0.9708\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0181 - accuracy: 0.9874 - val_loss: 0.2737 - val_accuracy: 0.9708\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0190 - accuracy: 0.9799 - val_loss: 0.2741 - val_accuracy: 0.9708\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0267 - accuracy: 0.9774 - val_loss: 0.2747 - val_accuracy: 0.9708\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0196 - accuracy: 0.9799 - val_loss: 0.2757 - val_accuracy: 0.9708\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0356 - accuracy: 0.9648 - val_loss: 0.2780 - val_accuracy: 0.9708\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0186 - accuracy: 0.9874 - val_loss: 0.2804 - val_accuracy: 0.9708\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0116 - accuracy: 0.9925 - val_loss: 0.2827 - val_accuracy: 0.9708\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0323 - accuracy: 0.9724 - val_loss: 0.2848 - val_accuracy: 0.9708\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0275 - accuracy: 0.9799 - val_loss: 0.2872 - val_accuracy: 0.9708\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0164 - accuracy: 0.9849 - val_loss: 0.2898 - val_accuracy: 0.9708\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0225 - accuracy: 0.9849 - val_loss: 0.2924 - val_accuracy: 0.9708\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0151 - accuracy: 0.9899 - val_loss: 0.2948 - val_accuracy: 0.9708\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0210 - accuracy: 0.9774 - val_loss: 0.2973 - val_accuracy: 0.9708\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0120 - accuracy: 0.9925 - val_loss: 0.3012 - val_accuracy: 0.9708\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0272 - accuracy: 0.9724 - val_loss: 0.3059 - val_accuracy: 0.9708\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0383 - accuracy: 0.9698 - val_loss: 0.3101 - val_accuracy: 0.9708\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0095 - accuracy: 0.9950 - val_loss: 0.3135 - val_accuracy: 0.9708\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0218 - accuracy: 0.9824 - val_loss: 0.3166 - val_accuracy: 0.9708\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0175 - accuracy: 0.9849 - val_loss: 0.3194 - val_accuracy: 0.9708\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0196 - accuracy: 0.9824 - val_loss: 0.3210 - val_accuracy: 0.9708\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0281 - accuracy: 0.9724 - val_loss: 0.3206 - val_accuracy: 0.9708\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0289 - accuracy: 0.9774 - val_loss: 0.3208 - val_accuracy: 0.9708\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0207 - accuracy: 0.9824 - val_loss: 0.3213 - val_accuracy: 0.9708\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0293 - accuracy: 0.9799 - val_loss: 0.3220 - val_accuracy: 0.9708\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0120 - accuracy: 0.9899 - val_loss: 0.3228 - val_accuracy: 0.9708\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0108 - accuracy: 0.9899 - val_loss: 0.3238 - val_accuracy: 0.9708\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0157 - accuracy: 0.9874 - val_loss: 0.3251 - val_accuracy: 0.9708\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0198 - accuracy: 0.9849 - val_loss: 0.3271 - val_accuracy: 0.9708\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0264 - accuracy: 0.9673 - val_loss: 0.3290 - val_accuracy: 0.9708\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0108 - accuracy: 0.9925 - val_loss: 0.3308 - val_accuracy: 0.9708\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0235 - accuracy: 0.9824 - val_loss: 0.3322 - val_accuracy: 0.9708\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 0.0125 - accuracy: 0.9874 - val_loss: 0.3337 - val_accuracy: 0.9708\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0100 - accuracy: 0.9950 - val_loss: 0.3342 - val_accuracy: 0.9708\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0166 - accuracy: 0.9824 - val_loss: 0.3344 - val_accuracy: 0.9708\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0228 - accuracy: 0.9824 - val_loss: 0.3324 - val_accuracy: 0.9708\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0220 - accuracy: 0.9849 - val_loss: 0.3280 - val_accuracy: 0.9708\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0268 - accuracy: 0.9799 - val_loss: 0.3247 - val_accuracy: 0.9708\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0130 - accuracy: 0.9899 - val_loss: 0.3244 - val_accuracy: 0.9708\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0114 - accuracy: 0.9899 - val_loss: 0.3240 - val_accuracy: 0.9708\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0167 - accuracy: 0.9874 - val_loss: 0.3244 - val_accuracy: 0.9708\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0169 - accuracy: 0.9849 - val_loss: 0.3249 - val_accuracy: 0.9708\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0216 - accuracy: 0.9874 - val_loss: 0.3237 - val_accuracy: 0.9708\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0159 - accuracy: 0.9899 - val_loss: 0.3223 - val_accuracy: 0.9708\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0160 - accuracy: 0.9849 - val_loss: 0.3217 - val_accuracy: 0.9708\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0162 - accuracy: 0.9874 - val_loss: 0.3299 - val_accuracy: 0.9708\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0118 - accuracy: 0.9874 - val_loss: 0.3372 - val_accuracy: 0.9708\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0137 - accuracy: 0.9874 - val_loss: 0.3428 - val_accuracy: 0.9708\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0135 - accuracy: 0.9849 - val_loss: 0.3466 - val_accuracy: 0.9708\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0165 - accuracy: 0.9849 - val_loss: 0.3494 - val_accuracy: 0.9708\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0330 - accuracy: 0.9749 - val_loss: 0.3519 - val_accuracy: 0.9649\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0150 - accuracy: 0.9874 - val_loss: 0.3544 - val_accuracy: 0.9649\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0258 - accuracy: 0.9799 - val_loss: 0.3570 - val_accuracy: 0.9649\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9649\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0173 - accuracy: 0.9849 - val_loss: 0.3621 - val_accuracy: 0.9649\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0158 - accuracy: 0.9849 - val_loss: 0.3638 - val_accuracy: 0.9649\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0081 - accuracy: 0.9950 - val_loss: 0.3656 - val_accuracy: 0.9649\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0262 - accuracy: 0.9749 - val_loss: 0.3675 - val_accuracy: 0.9649\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0212 - accuracy: 0.9874 - val_loss: 0.3697 - val_accuracy: 0.9649\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0114 - accuracy: 0.9925 - val_loss: 0.3717 - val_accuracy: 0.9649\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0094 - accuracy: 0.9899 - val_loss: 0.3737 - val_accuracy: 0.9649\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0175 - accuracy: 0.9899 - val_loss: 0.3756 - val_accuracy: 0.9649\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0255 - accuracy: 0.9774 - val_loss: 0.3755 - val_accuracy: 0.9649\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0149 - accuracy: 0.9849 - val_loss: 0.3733 - val_accuracy: 0.9649\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0177 - accuracy: 0.9874 - val_loss: 0.3711 - val_accuracy: 0.9708\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0312 - accuracy: 0.9673 - val_loss: 0.3695 - val_accuracy: 0.9708\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0225 - accuracy: 0.9799 - val_loss: 0.3678 - val_accuracy: 0.9708\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0223 - accuracy: 0.9774 - val_loss: 0.3654 - val_accuracy: 0.9708\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0196 - accuracy: 0.9799 - val_loss: 0.3613 - val_accuracy: 0.9708\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0207 - accuracy: 0.9774 - val_loss: 0.3554 - val_accuracy: 0.9708\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0117 - accuracy: 0.9874 - val_loss: 0.3512 - val_accuracy: 0.9708\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0317 - accuracy: 0.9698 - val_loss: 0.3469 - val_accuracy: 0.9708\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0182 - accuracy: 0.9824 - val_loss: 0.3433 - val_accuracy: 0.9708\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0211 - accuracy: 0.9774 - val_loss: 0.3419 - val_accuracy: 0.9708\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0174 - accuracy: 0.9799 - val_loss: 0.3413 - val_accuracy: 0.9708\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0173 - accuracy: 0.9874 - val_loss: 0.3418 - val_accuracy: 0.9708\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0205 - accuracy: 0.9799 - val_loss: 0.3429 - val_accuracy: 0.9766\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0238 - accuracy: 0.9698 - val_loss: 0.3439 - val_accuracy: 0.9766\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0130 - accuracy: 0.9874 - val_loss: 0.3449 - val_accuracy: 0.9766\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0147 - accuracy: 0.9824 - val_loss: 0.3458 - val_accuracy: 0.9708\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 185ms/step - loss: 0.0161 - accuracy: 0.9824 - val_loss: 0.3465 - val_accuracy: 0.9708\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0151 - accuracy: 0.9824 - val_loss: 0.3473 - val_accuracy: 0.9708\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0219 - accuracy: 0.9849 - val_loss: 0.3479 - val_accuracy: 0.9708\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0336 - accuracy: 0.9925 - val_loss: 0.3479 - val_accuracy: 0.9708\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0113 - accuracy: 0.9925 - val_loss: 0.3486 - val_accuracy: 0.9708\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0089 - accuracy: 0.9925 - val_loss: 0.3498 - val_accuracy: 0.9708\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0107 - accuracy: 0.9899 - val_loss: 0.3510 - val_accuracy: 0.9708\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0071 - accuracy: 0.9950 - val_loss: 0.3525 - val_accuracy: 0.9708\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0166 - accuracy: 0.9824 - val_loss: 0.3538 - val_accuracy: 0.9708\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0165 - accuracy: 0.9874 - val_loss: 0.3542 - val_accuracy: 0.9708\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0222 - accuracy: 0.9799 - val_loss: 0.3540 - val_accuracy: 0.9708\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0160 - accuracy: 0.9849 - val_loss: 0.3541 - val_accuracy: 0.9708\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0282 - accuracy: 0.9824 - val_loss: 0.3541 - val_accuracy: 0.9708\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0205 - accuracy: 0.9799 - val_loss: 0.3538 - val_accuracy: 0.9708\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0147 - accuracy: 0.9849 - val_loss: 0.3545 - val_accuracy: 0.9708\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0125 - accuracy: 0.9899 - val_loss: 0.3568 - val_accuracy: 0.9708\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0127 - accuracy: 0.9874 - val_loss: 0.3595 - val_accuracy: 0.9649\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0164 - accuracy: 0.9799 - val_loss: 0.3625 - val_accuracy: 0.9649\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0189 - accuracy: 0.9824 - val_loss: 0.3677 - val_accuracy: 0.9649\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0176 - accuracy: 0.9849 - val_loss: 0.3727 - val_accuracy: 0.9649\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0131 - accuracy: 0.9899 - val_loss: 0.3771 - val_accuracy: 0.9649\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0058 - accuracy: 0.9950 - val_loss: 0.3814 - val_accuracy: 0.9649\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0129 - accuracy: 0.9874 - val_loss: 0.3854 - val_accuracy: 0.9649\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0168 - accuracy: 0.9799 - val_loss: 0.3894 - val_accuracy: 0.9649\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0142 - accuracy: 0.9849 - val_loss: 0.3930 - val_accuracy: 0.9649\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0140 - accuracy: 0.9824 - val_loss: 0.3961 - val_accuracy: 0.9649\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0142 - accuracy: 0.9849 - val_loss: 0.3988 - val_accuracy: 0.9649\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0109 - accuracy: 0.9899 - val_loss: 0.4011 - val_accuracy: 0.9649\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0164 - accuracy: 0.9849 - val_loss: 0.4034 - val_accuracy: 0.9649\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0166 - accuracy: 0.9849 - val_loss: 0.4057 - val_accuracy: 0.9649\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0282 - accuracy: 0.9774 - val_loss: 0.4080 - val_accuracy: 0.9649\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0197 - accuracy: 0.9774 - val_loss: 0.4103 - val_accuracy: 0.9649\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0232 - accuracy: 0.9774 - val_loss: 0.4121 - val_accuracy: 0.9649\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0130 - accuracy: 0.9874 - val_loss: 0.4147 - val_accuracy: 0.9649\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0098 - accuracy: 0.9899 - val_loss: 0.4174 - val_accuracy: 0.9649\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0151 - accuracy: 0.9849 - val_loss: 0.4200 - val_accuracy: 0.9649\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0098 - accuracy: 0.9925 - val_loss: 0.4223 - val_accuracy: 0.9649\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0104 - accuracy: 0.9899 - val_loss: 0.4243 - val_accuracy: 0.9649\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0105 - accuracy: 0.9874 - val_loss: 0.4259 - val_accuracy: 0.9649\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0264 - accuracy: 0.9799 - val_loss: 0.4271 - val_accuracy: 0.9649\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0152 - accuracy: 0.9849 - val_loss: 0.4283 - val_accuracy: 0.9649\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0062 - accuracy: 0.9950 - val_loss: 0.4294 - val_accuracy: 0.9649\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0090 - accuracy: 0.9925 - val_loss: 0.4304 - val_accuracy: 0.9649\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0190 - accuracy: 0.9774 - val_loss: 0.4305 - val_accuracy: 0.9649\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0104 - accuracy: 0.9899 - val_loss: 0.4308 - val_accuracy: 0.9649\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.4312 - val_accuracy: 0.9649\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0224 - accuracy: 0.9975 - val_loss: 0.4271 - val_accuracy: 0.9649\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.4192 - val_accuracy: 0.9649\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 187ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9649\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0256 - accuracy: 0.9975 - val_loss: 0.4065 - val_accuracy: 0.9649\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9708\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.3936 - val_accuracy: 0.9708\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.9708\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9708\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.9708\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0179 - accuracy: 0.9975 - val_loss: 0.3868 - val_accuracy: 0.9708\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3863 - val_accuracy: 0.9708\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9708\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.9708\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.9708\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9708\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.9708\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9708\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9708\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.9708\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.3909 - val_accuracy: 0.9708\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9708\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.3918 - val_accuracy: 0.9708\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9708\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9708\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.3941 - val_accuracy: 0.9708\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 0.3964 - val_accuracy: 0.9708\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.4001 - val_accuracy: 0.9708\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0150 - accuracy: 0.9975 - val_loss: 0.4079 - val_accuracy: 0.9649\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.9649\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.9649\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.4331 - val_accuracy: 0.9649\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0199 - accuracy: 0.9975 - val_loss: 0.4413 - val_accuracy: 0.9649\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9649\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9708\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.4580 - val_accuracy: 0.9708\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9708\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0263 - accuracy: 0.9975 - val_loss: 0.4638 - val_accuracy: 0.9708\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9708\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9708\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9708\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.9708\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9708\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.9708\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0133 - accuracy: 0.9975 - val_loss: 0.4768 - val_accuracy: 0.9708\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9708\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9708\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.4772 - val_accuracy: 0.9708\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9708\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.9708\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0219 - accuracy: 0.9975 - val_loss: 0.4667 - val_accuracy: 0.9708\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9708\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 0.4476 - val_accuracy: 0.9766\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9766\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9766\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9766\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9766\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9766\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.4543 - val_accuracy: 0.9766\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0163 - accuracy: 0.9975 - val_loss: 0.4550 - val_accuracy: 0.9766\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.4555 - val_accuracy: 0.9766\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9766\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0210 - accuracy: 0.9975 - val_loss: 0.4547 - val_accuracy: 0.9766\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0115 - accuracy: 0.9950 - val_loss: 0.4541 - val_accuracy: 0.9766\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.4543 - val_accuracy: 0.9766\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9708\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0160 - accuracy: 0.9975 - val_loss: 0.4554 - val_accuracy: 0.9708\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0220 - accuracy: 0.9975 - val_loss: 0.4559 - val_accuracy: 0.9708\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9708\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0169 - accuracy: 0.9925 - val_loss: 0.4568 - val_accuracy: 0.9708\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9708\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.4580 - val_accuracy: 0.9708\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0152 - accuracy: 0.9975 - val_loss: 0.4578 - val_accuracy: 0.9708\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.9708\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.4579 - val_accuracy: 0.9708\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.4582 - val_accuracy: 0.9708\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 0.4583 - val_accuracy: 0.9708\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.9708\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9649\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9649\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.4750 - val_accuracy: 0.9649\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0210 - accuracy: 0.9975 - val_loss: 0.4789 - val_accuracy: 0.9649\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9649\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 0.4846 - val_accuracy: 0.9649\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9649\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4887 - val_accuracy: 0.9649\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 0.4907 - val_accuracy: 0.9649\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.4918 - val_accuracy: 0.9649\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9649\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9649\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9649\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.4974 - val_accuracy: 0.9649\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.4989 - val_accuracy: 0.9649\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.5005 - val_accuracy: 0.9649\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9649\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.9649\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.9649\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0173 - accuracy: 0.9975 - val_loss: 0.5082 - val_accuracy: 0.9649\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.9649\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 189ms/step - loss: 0.0406 - accuracy: 0.9975 - val_loss: 0.5090 - val_accuracy: 0.9649\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.9649\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9649\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.9649\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.9649\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.9649\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.9649\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 0.4906 - val_accuracy: 0.9649\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.9708\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9708\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.4904 - val_accuracy: 0.9708\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 0.4911 - val_accuracy: 0.9708\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.4924 - val_accuracy: 0.9708\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.9708\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.9708\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.9708\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9708\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9708\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.9708\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.9708\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.9708\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.9708\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.9708\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.9708\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.9708\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.9708\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.5161 - val_accuracy: 0.9649\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.5179 - val_accuracy: 0.9649\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0214 - accuracy: 0.9975 - val_loss: 0.5190 - val_accuracy: 0.9649\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0408 - accuracy: 0.9975 - val_loss: 0.5202 - val_accuracy: 0.9649\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.5215 - val_accuracy: 0.9649\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.9649\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0241 - accuracy: 0.9975 - val_loss: 0.5244 - val_accuracy: 0.9649\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.5258 - val_accuracy: 0.9649\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0157 - accuracy: 0.9975 - val_loss: 0.5282 - val_accuracy: 0.9649\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.5301 - val_accuracy: 0.9649\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 0.5319 - val_accuracy: 0.9649\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.9649\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5347 - val_accuracy: 0.9649\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0208 - accuracy: 0.9950 - val_loss: 0.5362 - val_accuracy: 0.9649\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9649\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0134 - accuracy: 0.9950 - val_loss: 0.5398 - val_accuracy: 0.9649\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5411 - val_accuracy: 0.9649\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.9649\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0177 - accuracy: 0.9975 - val_loss: 0.5434 - val_accuracy: 0.9649\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5445 - val_accuracy: 0.9649\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.9649\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.9649\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 192ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.5477 - val_accuracy: 0.9649\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.5489 - val_accuracy: 0.9649\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.5499 - val_accuracy: 0.9649\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.5515 - val_accuracy: 0.9649\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.9649\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.9649\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.9649\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.5532 - val_accuracy: 0.9649\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.9649\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5548 - val_accuracy: 0.9649\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.9649\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.5614 - val_accuracy: 0.9649\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.9649\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.5660 - val_accuracy: 0.9649\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.9649\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5698 - val_accuracy: 0.9649\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.5716 - val_accuracy: 0.9649\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.5732 - val_accuracy: 0.9649\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.9649\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.5770 - val_accuracy: 0.9649\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0267 - accuracy: 0.9975 - val_loss: 0.5776 - val_accuracy: 0.9649\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.9649\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.9649\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0172 - accuracy: 0.9975 - val_loss: 0.5754 - val_accuracy: 0.9649\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5747 - val_accuracy: 0.9649\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0158 - accuracy: 0.9975 - val_loss: 0.5742 - val_accuracy: 0.9649\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.5739 - val_accuracy: 0.9649\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5739 - val_accuracy: 0.9649\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.5739 - val_accuracy: 0.9649\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.9649\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.9649\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.9649\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.9649\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.5742 - val_accuracy: 0.9649\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.5749 - val_accuracy: 0.9649\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0224 - accuracy: 0.9975 - val_loss: 0.5753 - val_accuracy: 0.9649\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.5767 - val_accuracy: 0.9649\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0156 - accuracy: 0.9975 - val_loss: 0.5783 - val_accuracy: 0.9649\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.9649\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5822 - val_accuracy: 0.9649\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0223 - accuracy: 0.9975 - val_loss: 0.5855 - val_accuracy: 0.9649\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.9649\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0128 - accuracy: 0.9975 - val_loss: 0.5907 - val_accuracy: 0.9649\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0202 - accuracy: 0.9975 - val_loss: 0.5911 - val_accuracy: 0.9649\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5908 - val_accuracy: 0.9649\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.5914 - val_accuracy: 0.9649\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5927 - val_accuracy: 0.9708\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.9708\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 184ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.5958 - val_accuracy: 0.9708\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.5978 - val_accuracy: 0.9708\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.6000 - val_accuracy: 0.9708\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0175 - accuracy: 0.9975 - val_loss: 0.5994 - val_accuracy: 0.9708\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5967 - val_accuracy: 0.9708\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 0.5948 - val_accuracy: 0.9708\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0124 - accuracy: 0.9975 - val_loss: 0.5945 - val_accuracy: 0.9708\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.5957 - val_accuracy: 0.9708\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.9708\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.9708\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.9649\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.9649\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.9649\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.9649\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.9649\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.9649\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.9649\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.9649\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9649\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.6077 - val_accuracy: 0.9649\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.9649\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.6092 - val_accuracy: 0.9649\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.6099 - val_accuracy: 0.9649\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 0.9649\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.9649\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.9649\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.6130 - val_accuracy: 0.9649\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.6139 - val_accuracy: 0.9649\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.9649\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0110 - accuracy: 0.9950 - val_loss: 0.6164 - val_accuracy: 0.9649\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0147 - accuracy: 0.9975 - val_loss: 0.6178 - val_accuracy: 0.9649\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.9649\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.9649\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.9649\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 0.6230 - val_accuracy: 0.9649\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.9649\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.9649\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.9649\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.9649\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.9649\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.6263 - val_accuracy: 0.9649\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6268 - val_accuracy: 0.9649\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6273 - val_accuracy: 0.9649\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.6277 - val_accuracy: 0.9649\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.6283 - val_accuracy: 0.9649\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0128 - accuracy: 0.9975 - val_loss: 0.6298 - val_accuracy: 0.9649\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.6308 - val_accuracy: 0.9649\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.9649\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 196ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.9649\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.6287 - val_accuracy: 0.9649\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6247 - val_accuracy: 0.9649\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.6218 - val_accuracy: 0.9649\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.9649\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.6177 - val_accuracy: 0.9649\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6164 - val_accuracy: 0.9649\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.6146 - val_accuracy: 0.9649\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9649\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.9649\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.6153 - val_accuracy: 0.9649\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.9649\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.6138 - val_accuracy: 0.9649\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.9649\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9649\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.6123 - val_accuracy: 0.9649\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.6113 - val_accuracy: 0.9649\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.9708\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.9708\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.9708\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.6135 - val_accuracy: 0.9708\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.9708\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.6161 - val_accuracy: 0.9708\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.9708\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.9708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5ae6fef320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ix4cJH23YQOL",
        "outputId": "261c8bdd-8eef-47c3-8543-4abda595f7fc"
      },
      "source": [
        "loss_df=pd.DataFrame(model.history.history)\r\n",
        "loss_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.043326</td>\n",
              "      <td>0.984925</td>\n",
              "      <td>0.124641</td>\n",
              "      <td>0.976608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.040121</td>\n",
              "      <td>0.979900</td>\n",
              "      <td>0.124993</td>\n",
              "      <td>0.976608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.036997</td>\n",
              "      <td>0.992462</td>\n",
              "      <td>0.125402</td>\n",
              "      <td>0.976608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.041278</td>\n",
              "      <td>0.989950</td>\n",
              "      <td>0.125856</td>\n",
              "      <td>0.976608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.041993</td>\n",
              "      <td>0.987437</td>\n",
              "      <td>0.126797</td>\n",
              "      <td>0.976608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy\n",
              "0  0.043326  0.984925  0.124641      0.976608\n",
              "1  0.040121  0.979900  0.124993      0.976608\n",
              "2  0.036997  0.992462  0.125402      0.976608\n",
              "3  0.041278  0.989950  0.125856      0.976608\n",
              "4  0.041993  0.987437  0.126797      0.976608"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR6_8cVWX3eu",
        "outputId": "d6dae522-8f69-4c3d-903b-7a75e21a299f"
      },
      "source": [
        "predictions=model.predict_classes(X_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEq-mq25aKUV",
        "outputId": "4bc1649d-619f-4471-d518-beb34ea46886"
      },
      "source": [
        "print('Confusion matrix \\n',confusion_matrix(y_test,predictions))\r\n",
        "print('\\n')\r\n",
        "print('classification report\\n',classification_report(y_test,predictions))\r\n",
        "print('\\n')\r\n",
        "print('Accuracy score\\n',accuracy_score(y_test,predictions))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix \n",
            " [[ 63   3]\n",
            " [  2 103]]\n",
            "\n",
            "\n",
            "classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96        66\n",
            "           1       0.97      0.98      0.98       105\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.97      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n",
            "\n",
            "\n",
            "Accuracy score\n",
            " 0.9707602339181286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgk0yO6ubl7r"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikr0714VbllG",
        "outputId": "4221ccc5-ba88-42e4-d0e1-9af091b7c0d0"
      },
      "source": [
        "lg_model=LogisticRegression()\r\n",
        "lg_model.fit(X_train,y_train)\r\n",
        "\r\n",
        "predictions=model.predict_classes(X_test)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImF64Q_Fb-_8",
        "outputId": "fbc87a8d-8e29-41d9-c383-ba6d1d1a85a6"
      },
      "source": [
        "print('Confusion matrix \\n',confusion_matrix(y_test,predictions))\r\n",
        "print('\\n')\r\n",
        "print('classification report\\n',classification_report(y_test,predictions))\r\n",
        "print('\\n')\r\n",
        "print('Accuracy score\\n',accuracy_score(y_test,predictions))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix \n",
            " [[ 63   3]\n",
            " [  2 103]]\n",
            "\n",
            "\n",
            "classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96        66\n",
            "           1       0.97      0.98      0.98       105\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.97      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n",
            "\n",
            "\n",
            "Accuracy score\n",
            " 0.9707602339181286\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}